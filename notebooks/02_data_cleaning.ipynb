{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0969ed",
   "metadata": {},
   "source": [
    "# TMDB Data Cleaning & Preprocessing\n",
    "\n",
    "This notebook transforms raw JSON movie data into clean, analysis-ready datasets.\n",
    "\n",
    "## Objectives\n",
    "1. Load raw JSON files from `data/raw/`\n",
    "2. Extract and flatten nested JSON structures\n",
    "3. Clean data types and handle missing values\n",
    "4. Apply quality filters\n",
    "5. Add derived features (ROI, profit, release year)\n",
    "6. Save cleaned data to `data/processed/`\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path and set working directory\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "from src.transform.pipeline import DataCleaningPipeline\n",
    "from src.utils.helpers import load_config, setup_logging\n",
    "\n",
    "# Setup logger for notebook\n",
    "logger = setup_logging(module_name='cleaning_notebook')\n",
    "logger.info(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c93ae4",
   "metadata": {},
   "source": [
    "## 1. Initialize Data Cleaner\n",
    "\n",
    "Load configuration and initialize the DataCleaner class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cleaner\n",
    "pipeline = DataCleaningPipeline(config_path=\"config/config.yaml\")\n",
    "\n",
    "logger.info(\"DataCleaningPipeline initialized\")\n",
    "logger.info(f\"  Raw data path: {pipeline.raw_data_path}\")\n",
    "logger.info(f\"  Interim data path: {pipeline.interim_data_path}\")\n",
    "logger.info(f\"  Processed data path: {pipeline.processed_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bbad4",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Raw Data\n",
    "\n",
    "Load raw JSON files and examine the initial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df_raw = pipeline.load_raw_data()\n",
    "\n",
    "logger.info(f\"Raw data shape: {df_raw.shape}\")\n",
    "logger.info(f\"Columns: {list(df_raw.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values before cleaning\n",
    "logger.info(\"\\n=== RAW DATA SUMMARY ===\")\n",
    "logger.info(f\"Total movies: {len(df_raw)}\")\n",
    "logger.info(f\"Total columns: {len(df_raw.columns)}\")\n",
    "logger.info(f\"\\nMissing values:\")\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = (missing / len(df_raw) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9e9c2",
   "metadata": {},
   "source": [
    "## 3. Run Complete Cleaning Pipeline\n",
    "\n",
    "Execute the full data cleaning process:\n",
    "- Extract nested JSON fields\n",
    "- Convert data types\n",
    "- Handle missing/unrealistic values\n",
    "- Apply quality filters\n",
    "- Add derived features\n",
    "- Reorder columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b30d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete cleaning pipeline\n",
    "df_cleaned = pipeline.run(save_interim=True, save_final=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f5c71",
   "metadata": {},
   "source": [
    "## 4. Inspect Cleaned Data\n",
    "\n",
    "Examine the cleaned dataset structure and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbddfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned data\n",
    "logger.info(f\"\\n=== CLEANED DATA SUMMARY ===\")\n",
    "logger.info(f\"Total movies: {len(df_cleaned)}\")\n",
    "logger.info(f\"Total columns: {len(df_cleaned.columns)}\")\n",
    "logger.info(f\"Columns: {list(df_cleaned.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "logger.info(\"\\nData types:\")\n",
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in cleaned data\n",
    "missing = df_cleaned.isnull().sum()\n",
    "missing_pct = (missing / len(df_cleaned) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "missing_summary = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "logger.info(f\"\\nMissing values in cleaned data:\")\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b48e1",
   "metadata": {},
   "source": [
    "## 5. Data Quality Statistics\n",
    "\n",
    "Generate summary statistics for numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numeric columns\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "logger.info(f\"\\nNumeric columns: {list(numeric_cols)}\")\n",
    "\n",
    "df_cleaned[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check specific data quality metrics\n",
    "logger.info(\"\\n=== DATA QUALITY METRICS ===\")\n",
    "logger.info(f\"Date range: {df_cleaned['release_date'].min()} to {df_cleaned['release_date'].max()}\")\n",
    "logger.info(f\"Year range: {df_cleaned['release_year'].min()} to {df_cleaned['release_year'].max()}\")\n",
    "logger.info(f\"\\nBudget (in millions USD):\")\n",
    "logger.info(f\"  Mean: ${df_cleaned['budget_musd'].mean():.2f}M\")\n",
    "logger.info(f\"  Median: ${df_cleaned['budget_musd'].median():.2f}M\")\n",
    "logger.info(f\"  Max: ${df_cleaned['budget_musd'].max():.2f}M\")\n",
    "logger.info(f\"\\nRevenue (in millions USD):\")\n",
    "logger.info(f\"  Mean: ${df_cleaned['revenue_musd'].mean():.2f}M\")\n",
    "logger.info(f\"  Median: ${df_cleaned['revenue_musd'].median():.2f}M\")\n",
    "logger.info(f\"  Max: ${df_cleaned['revenue_musd'].max():.2f}M\")\n",
    "logger.info(f\"\\nROI:\")\n",
    "logger.info(f\"  Mean: {df_cleaned['roi'].mean():.2f}%\")\n",
    "logger.info(f\"  Median: {df_cleaned['roi'].median():.2f}%\")\n",
    "logger.info(f\"  Max: {df_cleaned['roi'].max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44573d6a",
   "metadata": {},
   "source": [
    "## 6. Explore Categorical Data\n",
    "\n",
    "Examine the distribution of key categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 languages\n",
    "logger.info(\"\\n=== TOP 10 ORIGINAL LANGUAGES ===\")\n",
    "df_cleaned['original_language'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common genres (from pipe-separated values)\n",
    "logger.info(\"\\n=== GENRE DISTRIBUTION ===\")\n",
    "# Split genres and count\n",
    "all_genres = df_cleaned['genres'].dropna().str.split('|').explode()\n",
    "all_genres.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection membership\n",
    "logger.info(f\"\\nMovies in collections: {df_cleaned['belongs_to_collection'].notna().sum()}\")\n",
    "logger.info(f\"Standalone movies: {df_cleaned['belongs_to_collection'].isna().sum()}\")\n",
    "\n",
    "# Top collections\n",
    "logger.info(\"\\n=== TOP 10 COLLECTIONS ===\")\n",
    "df_cleaned['belongs_to_collection'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69767027",
   "metadata": {},
   "source": [
    "## 7. Sample of Cleaned Data\n",
    "\n",
    "View a few complete records to verify data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample movies with key information\n",
    "sample_cols = ['title', 'release_year', 'genres', 'budget_musd', 'revenue_musd', \n",
    "               'roi', 'vote_average', 'director', 'cast']\n",
    "df_cleaned[sample_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed504ac4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data cleaning completed successfully! The cleaned dataset is now saved in:\n",
    "- **CSV**: `data/processed/movies_cleaned.csv`\n",
    "- **Parquet**: `data/processed/movies_cleaned.parquet`\n",
    "- **Interim**: `data/interim/movies_interim.csv`\n",
    "\n",
    "### Cleaning Steps Applied:\n",
    "1. ✓ Loaded raw JSON files\n",
    "2. ✓ Extracted nested structures (genres, cast, crew, etc.)\n",
    "3. ✓ Converted data types (dates, numeric values)\n",
    "4. ✓ Handled missing and unrealistic values\n",
    "5. ✓ Applied quality filters (duplicates, sparse data, non-released movies)\n",
    "6. ✓ Added derived features (ROI, profit, release year)\n",
    "7. ✓ Reordered columns for consistency\n",
    "\n",
    "### Next Steps:\n",
    "Proceed to `03_kpi_analysis.ipynb` for KPI calculations and analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
